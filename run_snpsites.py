#!/usr/bin/env python3

import os
import numpy as np
import pandas as pd
import feather
from Bio import SeqIO

"""
by David Brown (db) - 20221201
Adapted from "/Users/dbrow208/Documents/galick_gun/test_prokka_roary/final_scripts/3C_run_snpsites_make_snp_matrix.py"

Reference https://github.com/sanger-pathogens/snp-sites

'This application takes in a multi fasta alignment, finds all the SNP sites, then outputs the SNP sites in the following formats:

    -m  =   a multi fasta alignment,
    -v  =   VCF,
    -p  =   relaxed phylip format.
    -r  =   internal reference sequence
'

Input is a filepath to a multiFASTA alignment (DNA or protein)

Run within the 'binf_snp-sites' conda environment

PLEASE NOTE: The logic in 'makeMesquiteCharacters()' works as 'snp-sites' output FASTA files are not line wrapped.
The logic could break if a multiFASTA with character limits per line is passed!!

TODO:
- WIP "muts_domains_dict" logic for collapsing SNP positions into possible domains
"""

###
# VARIABLES - Make changes here
# # A filepath string to an input multiFASTA (can be gzipped)
this_input              =   "/scratch/dbrow208/galick_gun_working_dir/subset_900/results_Roary_no_split/subset_900_ns_protein_mutS.faa"
# # A filepath string to an feather format pandas dataframe of Roary outputs, binary presence/absence of a given annotated gene. (generated by /Users/dbrow208/Documents/galick_gun/test_prokka_roary/final_scripts/4_prepare_data_matrices.py)
this_roary              =   "/scratch/dbrow208/galick_gun_working_dir/subset_900/results_Roary_no_split/20221202_snp_sites/subset_900_no_split_core_and_soft_core.ftr"
# Designate output filepath string (do NOT include suffixes) for the snp-sites program calls
this_snp_sites_output   =   "/scratch/dbrow208/galick_gun_working_dir/subset_900/results_Roary_no_split/20221209_snp_sites/ns_prot_mutS"

###
# FUNCTIONS

# A Python function that calls the 'snp-sites' program an input multiFASTA alignment file (can be gzipped) and outputs files to a directory (indicated by filepath)
def callSNPsites( input_multiFASTA, output_filepath):
    """
    Inputs:
    -   aligned multiFASTA file (can be gzipped)
    -   desired path for the 3 output files (string)

    Files created:
    -   MultiFASTA, only containing SNPs for machine learning and parsimony trees. (a 'SNP matrix')
    -   Relaxed Phylip, for RAxML trees.
    -   VCF, for positional references of the SNPs.
    -   FASTA, an internal reference sequence

    Returns:
    -   three strings, containing the output filepaths
    """
    # Builds the output filepath strings
    name_multiFASTA = output_filepath + ".fasta"
    name_phylip     = output_filepath + ".phy"
    name_vcf        = output_filepath + ".vcf"
    # Builds the snp-sites call strings from the inputs
    multiFASTA_call = "snp-sites -m -o " + name_multiFASTA + " " + str(input_multiFASTA)
    phylip_call     = "snp-sites -p -o " + name_phylip + " " + str(input_multiFASTA)
    vcf_call        = "snp-sites -v -o " + name_vcf + " " + str(input_multiFASTA)
    # Call 'snp-sites'
    os.system(multiFASTA_call)
    os.system(phylip_call)
    os.system(vcf_call)
    # Returns the string filepaths of the three created files.
    return(name_multiFASTA, name_phylip, name_vcf)

# A Python function that transforms an aligned multiFASTA of SNPs into a pandas data frame, saved in feather format. Uses a VCF file as reference.
def makePandasSNPmatrix( some_multiFASTA, some_vcf, some_output_filepath ):
    """
    Inputs:
    -   aligned multiFASTA file containing only SNPs (cannot be gzipped)
    -   the VCF file associated with that multiFASTA file (usually from snp-sites)
    -   desired path for the output pandas feather data (string)

    Files created:
    -   pandas data frame of the SNP matrix in both feather and tab-separated formats (rows are sequences, columns are positions)
    """
    # Make the rows for the data frame as the identifier followed by the SNPs of that sequence.
    these_rows = []
    with open( some_multiFASTA, "r" ) as file1:
        these_rows = file1.readlines()
        # Strip formatting
        these_rows = [ i.lstrip(">") for i in these_rows ]
        these_rows = [ i.rstrip('\n') for i in these_rows ]
        # Item strings at even indices are cast to lists, while item strings at odd indices are split into lists of characters
        these_rows = [ [these_rows[i]] if i%2==0 else list(these_rows[i]) for i in range(0, len(these_rows)) ]
        # The odd indices (SNPs) are added to the corresponding even indices (sequence name) to create the rows.
        these_rows = [ these_rows[i] + these_rows[i+1] for i in range(0, len(these_rows), 2)]

    # Make the columns for the data frame. Extract the reference SNP positions from the VCF file.
    vcf_df = pd.read_csv(some_vcf, skiprows=3, sep="\t")    # Skips the three heading rows.
    these_cols = ['asm_acc']                                # Assigned for continuity across data. Should match the identifier in your main data frame or table.
    these_pos = vcf_df['POS'].tolist()                      # Capture the SNP positions column.
    these_pos = [ "pos_" + str(i).zfill(3) for i in these_pos ]      # Add a prefix for easier identification later.
    these_cols.extend(these_pos)

    # Build the dataframe
    df = pd.DataFrame(these_rows, columns=these_cols)
    # Save the outputs
    output_fp_ftr   = some_output_filepath + ".SNPmatrix.ftr"
    output_fp_tsv   = some_output_filepath + ".SNPmatrix.tsv"
    df.to_feather(output_fp_ftr)
    df.to_csv(output_fp_tsv, sep="\t")


# A Python function that creates a tab-separated file of information useful in Mesquite. Takes an aligned multiFASTA of SNPs. Uses a reference sequence created by "callSNPsites()" above.
def makeMesquiteCharacters( this_input_filepath, this_vcf, these_genes, this_output_filepath ):
    """
    Inputs:
    -   aligned multiFASTA file containing only SNPs (cannot be gzipped)
    -   the VCF file (to create a reference sequence associated with that multiFASTA file [usually from snp-sites])
    -   the feather format pandas dataframe containing binary presence/absence gene information from the pangenome calculated by Roary
    -   desired path for the output tab-separated file (string)

    Files created:
    -   tab-separated files with and without column names of information for Mesquite (rows are sequences/end nodes, columns are characters)
        -- columns are:
            * sequence identifier (no underscores)
            * sequence
            * SNP pattern group identifier (either Mesquite categorical character or integer)
            * number of SNPs per each sequence that differ from the reference sequence
            * all other columns represent positions (extending up to the length of the input reference sequence) with the binary presence/absence of a base identical to that of the reference sequence at that position
    -   tab-separated files of the above for Mesquite data types (binary, categorical, and continuous)
    """
    # (0-9, A-H, K-N, P-Z, a-h, k-n, p-z). J/j might be allowed, but not L/l? Please reference https://www.mesquiteproject.org/Characters%20&%20Matrices.html?GettingStartedPanel=open&TaxaTreesCharactersPanel=open
    allowed_mesquite_chars = [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        'A',
        'B',
        'C',
        'D',
        'E',
        'F',
        'G',
        'H',
        'K',
        'L',
        'M',
        'N',
        'P',
        'Q',
        'R',
        'S',
        'T',
        'U',
        'V',
        'W',
        'X',
        'Y',
        'Z',
        'a',
        'b',
        'c',
        'd',
        'e',
        'f',
        'g',
        'h',
        'k',
        'l',
        'm',
        'n',
        'p',
        'q',
        'r',
        's',
        't',
        'u',
        'v',
        'w',
        'x',
        'y',
        'z'
    ]
    
    # WIP Work on this logic later. Could be useful for binning. - db 20221202
    # Potentially use a while loop?
    # Please reference https://www.uniprot.org/uniprotkb/P23909/entry "Features"
    # Could be necessary to reduce ranges by 1 due to the "-" insertion at the beginning of the sequences. Also add a "not found" or "uncertain" output
    muts_domains_dict = {
        '0-23'      : 'feature 00 helix',
        '27-40'     : 'feature 01 beta strand',
        '41-51'     : 'feature 02 helix',
        '56-72'     : 'feature 03 beta strand',
        '73-85'     : 'feature 04 helix',
        '90-95'     : 'feature 05 beta strand',
        '99-101'    : 'feature 06 helix',
        '103-114'   : 'feature 07 beta strand',
        '116-118'   : 'feature 08 turn',
        '122-124'   : 'feature 09 helix',
        '133-148'   : 'feature 10 beta strand',
        '150-152'   : 'feature 11 turn',
        '155-158'   : 'feature 12 beta strand',
        '163-173'   : 'feature 13 helix',
        '176-181'   : 'feature 14 beta strand',
        '187-189'   : 'feature 15 helix',
        '190-192'   : 'feature 16 turn',
        '194-199'   : 'feature 17 beta strand',
        '201-217'   : 'feature 18 helix',
        '220-222'   : 'feature 19 beta strand',
        '223-248'   : 'feature 20 helix',
        '249-251'   : 'feature 21 beta strand',
        '252-254'   : 'feature 22 helix',
        '258-260'   : 'feature 23 beta strand',
        '263-276'   : 'feature 24 helix',
        '279-290'   : 'feature 25 beta strand',
        '291-410'   : 'feature 26 helix',
        '419-421'   : 'feature 27 beta strand',
        '431-458'   : 'feature 28 helix',
        '464-468'   : 'feature 29 beta strand',
        '469-471'   : 'feature 30 turn',
        '472-478'   : 'feature 31 beta strand',
        '479-482'   : 'feature 32 helix',
        '490-502'   : 'feature 33 beta strand',
        '504-564'   : 'feature 34 helix',
        '570-583'   : 'feature 35 beta strand',
        '588-591'   : 'feature 36 helix',
        '592-613'   : 'feature 37 beta strand',
        '620-634'   : 'feature 38 helix',
        '635-637'   : 'feature 39 turn',
        '640-657'   : 'feature 40 beta strand',
        '663-666'   : 'feature 41 turn',
        '671-683'   : 'feature 42 helix',
        '688-694'   : 'feature 43 beta strand',
        '695-698'   : 'feature 44 turn',
        '699-702'   : 'feature 45 beta strand',
        '703-717'   : 'feature 46 helix',
        '722-726'   : 'feature 47 beta strand',
        '730-738'   : 'feature 48 helix',
        '742-765'   : 'feature 49 beta strand',
        '772-831'   : 'feature 50 helix',
        '834-836'   : 'feature 51 turn',
        '839-852'   : 'feature 52 helix',
    }
    
    id_seq_dict = {}
    ### NOTE: in the data, there was one accession "GCF_003667425" that was duplicated into "GCF_003667425_00982" and "GCF_003667425_00983", each fragmented.
    # See below for fix
    fix_placeholder = []
    for seq_record in SeqIO.parse(this_input_filepath, "fasta"):
        if not seq_record.id.startswith('GCF_003667425'):
            reformat_id = " ".join(seq_record.id.split("_")[:2])
            id_seq_dict[reformat_id] = seq_record.seq
        # Here, to fix the fragmentation, they are explicitly combined under "GCF 003667425". Previous data formats are left unchanged. - db 20221202
        else:
            fix_placeholder.append(str(seq_record.seq))
            if len(fix_placeholder) == 2:
                reformat_id = " ".join(seq_record.id.split("_")[:2])
                fix_seqs = [ str(seq) for seq in fix_placeholder ]
                fix_seqs[0] = fix_seqs[0].replace("-", "")
                part_0, part_1, part_2 = fix_seqs[1].partition('TAT')
                combined = part_0 + part_1 + fix_seqs[0]
                id_seq_dict[reformat_id] = combined

    all_keys = id_seq_dict.keys()
    uniq_seqs = [ str(seq) for seq in id_seq_dict.values() ]
    uniq_seqs = list(set(uniq_seqs))
    print(len(uniq_seqs))
    #print(uniq_seqs)
    uniq_types = []
    try:
        uniq_types = [ allowed_mesquite_chars[i] for i in range(0,len(uniq_seqs)) ]
        print(len(uniq_types))
        #print(uniq_types)
    except:
        print("Number of unique sequences is greater than maximum number (", str(len(allowed_mesquite_chars)), ") of categorical characters\nallowed by the Mesquite Project software. Changing from characters to integers.")
        uniq_types = [ i for i in range(0,len(uniq_seqs)) ]
    # Dictionary to reference unique sequences and their assigned Mesquite character 
    seq_type_dict = dict(zip(uniq_seqs, uniq_types))

    # Check each position of each sequence against the reference sequence, recording binary absence/presence (0/1) and per sequence counts of total number of SNP variations from the reference sequence
    # Read in the VCF file
    ref_seq_df = pd.read_csv(this_vcf, sep='\t', header=3)
    # Identify and format the "REF" column as a string of characters
    reference_sequence = "".join(ref_seq_df['REF'].to_numpy().tolist())
    # Identify the position of the SNPs from the "POS" column
    pos_names = ref_seq_df['POS'].to_numpy().tolist()
    # Instantiate a dictionary to track counts of differences per sequence
    hold_counts = { k:0 for k in all_keys }
    # Populate per position column values for SNP differences from concsensus
    hold_columns = {}
    for pos in range(0, len(reference_sequence)):
        pos_list = []
        for key in all_keys:
            if id_seq_dict[key][pos] == reference_sequence[pos]:
                pos_list.append(1)
            else:
                pos_list.append(0)
                # Else if different, increment the count
                hold_counts[key] +=1
        col_name = "pos_" + str(pos_names[pos]).zfill(3)
        hold_columns[col_name] = pos_list
    hold_columns['asm_acc'] = all_keys

    # Read in the dataframe containing binary presence/absence data for specific genes within a subset of the pangenome as calculated by Roary
    comparison_df = pd.read_feather(these_genes)
    # Copy for safety to avoid "view" issues
    working_df = comparison_df.copy()
    # Add a reference column to "join on" by reformatting the "asm_acc"
    working_df['asm_acc'] = [ " ".join(i.split("_")[:2]) for i in working_df['index'].to_numpy().tolist() ]
    
    #print(comparison_df.columns.to_list())
    #print(comparison_df['index'].to_numpy())
    #print(out_join_df.MDR_bin.value_counts())
    
    # Fill the output dataframe
    out_df = pd.DataFrame()
    # A column of the reformatted (and ordered) sequence accessions 
    out_df['asm_acc'] = all_keys
    # A column of the sequences as strings
    out_df['seq_str'] = [ str(id_seq_dict[key]) for key in all_keys ]
    # A column of the SNP pattern unique groups
    out_df['snp_grp'] = [ "group " + str(seq_type_dict[str(id_seq_dict[key])]).zfill(2) for key in all_keys ]
    # A column of the per sequence total for number of SNPs different when compared against the internal reference
    out_df['snp_var'] = [ hold_counts[key] for key in all_keys ]
    # Set the index
    out_df.set_index('asm_acc')
    # All columns (per position) of the binary presence/absence of a sequence matching the reference at a given position
    pos_df = pd.DataFrame.from_dict(hold_columns)
    # Merge the dataframes
    out_pos_df = pd.merge(out_df, pos_df, on='asm_acc', how="left")
    # Subset the working dataframe to the desired columns, copying for safety
    temp_df = working_df[ ['asm_acc', 'MDR_bin']].copy()
    # Merge the dataframes
    out_join_df = pd.merge(out_pos_df, temp_df, on='asm_acc', how="left")
    # Write the main output files
    outfile_mesquite = this_output_filepath + ".forMesquite.tsv"
    out_join_df.to_csv( outfile_mesquite, index=False, header=False, sep="\t" )
    outfile_original = this_output_filepath + ".original.tsv"
    out_join_df.to_csv( outfile_original, index=False, header=True, sep="\t" )

    # Write character type based data subsets for Mesquite
    # Binary characters
    temp_aa = out_join_df.copy()
    temp_aa = temp_aa[['asm_acc', 'seq_str']]
    outfile_mesquite_aa = this_output_filepath + ".original.aa_sequence.tsv"
    temp_aa.to_csv( outfile_mesquite_aa, index=False, header=True, sep="\t" )
    # Binary characters
    temp_bin = out_join_df.copy()
    temp_bin = temp_bin.drop(['seq_str', 'snp_grp', 'snp_var'], axis=1)
    outfile_mesquite_bin = this_output_filepath + ".original.binary_chars.tsv"
    temp_bin.to_csv( outfile_mesquite_bin, index=False, header=True, sep="\t" )
    # Categorical characters
    temp_cat = out_join_df.copy()
    temp_cat = temp_cat[['asm_acc', 'snp_grp']]
    outfile_mesquite_cat = this_output_filepath + ".original.categorical_chars.tsv"
    temp_cat.to_csv( outfile_mesquite_cat, index=False, header=True, sep="\t" )
    # Continuous characters
    temp_cnt = out_join_df.copy()
    temp_cnt = temp_cnt[['asm_acc', 'snp_var']] 
    outfile_mesquite_cnt = this_output_filepath + ".original.continuous_chars.tsv"
    temp_cnt.to_csv( outfile_mesquite_cnt, index=False, header=True, sep="\t" )

###
# EXECUTION
this_multiFASTA, this_phylip, this_vcf  = callSNPsites( this_input, this_snp_sites_output )
makePandasSNPmatrix( this_multiFASTA, this_vcf, this_snp_sites_output )
makeMesquiteCharacters( this_multiFASTA, this_vcf, this_roary, this_snp_sites_output )
